[
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "stats",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "welch",
        "importPath": "scipy.signal",
        "description": "scipy.signal",
        "isExtraImport": true,
        "detail": "scipy.signal",
        "documentation": {}
    },
    {
        "label": "stft",
        "importPath": "scipy.signal",
        "description": "scipy.signal",
        "isExtraImport": true,
        "detail": "scipy.signal",
        "documentation": {}
    },
    {
        "label": "butter",
        "importPath": "scipy.signal",
        "description": "scipy.signal",
        "isExtraImport": true,
        "detail": "scipy.signal",
        "documentation": {}
    },
    {
        "label": "lfilter",
        "importPath": "scipy.signal",
        "description": "scipy.signal",
        "isExtraImport": true,
        "detail": "scipy.signal",
        "documentation": {}
    },
    {
        "label": "EpochsArray",
        "importPath": "mne",
        "description": "mne",
        "isExtraImport": true,
        "detail": "mne",
        "documentation": {}
    },
    {
        "label": "CSP",
        "importPath": "mne.decoding",
        "description": "mne.decoding",
        "isExtraImport": true,
        "detail": "mne.decoding",
        "documentation": {}
    },
    {
        "label": "Info",
        "importPath": "mne._fiff.meas_info",
        "description": "mne._fiff.meas_info",
        "isExtraImport": true,
        "detail": "mne._fiff.meas_info",
        "documentation": {}
    },
    {
        "label": "pywt",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pywt",
        "description": "pywt",
        "detail": "pywt",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Epochs",
        "importPath": "mne.epochs",
        "description": "mne.epochs",
        "isExtraImport": true,
        "detail": "mne.epochs",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "read_raw",
        "importPath": "mne.io",
        "description": "mne.io",
        "isExtraImport": true,
        "detail": "mne.io",
        "documentation": {}
    },
    {
        "label": "Raw",
        "importPath": "mne.io",
        "description": "mne.io",
        "isExtraImport": true,
        "detail": "mne.io",
        "documentation": {}
    },
    {
        "label": "read_raw_fif",
        "importPath": "mne.io",
        "description": "mne.io",
        "isExtraImport": true,
        "detail": "mne.io",
        "documentation": {}
    },
    {
        "label": "Raw",
        "importPath": "mne.io",
        "description": "mne.io",
        "isExtraImport": true,
        "detail": "mne.io",
        "documentation": {}
    },
    {
        "label": "read_raw_fif",
        "importPath": "mne.io",
        "description": "mne.io",
        "isExtraImport": true,
        "detail": "mne.io",
        "documentation": {}
    },
    {
        "label": "MultiHeadAttention",
        "kind": 6,
        "importPath": "model.NeuroX",
        "description": "model.NeuroX",
        "peekOfCode": "class MultiHeadAttention(nn.Module): \n  def __init__(self, d_in, d_out, ctx_len, dropout, num_heads, qkv_bias=False):\n    super().__init__()\n    assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n    self.d_out = d_out \n    self.num_heads = num_heads \n    self.head_dim = d_out // num_heads\n    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)",
        "detail": "model.NeuroX",
        "documentation": {}
    },
    {
        "label": "LayerNorm",
        "kind": 6,
        "importPath": "model.NeuroX",
        "description": "model.NeuroX",
        "peekOfCode": "class LayerNorm(nn.Module):\n  def __init__(self, emb_dim, ew_affine=True):\n    super().__init__() \n    self.eps = 1e-5 \n    self.ew_affine = ew_affine\n    if self.ew_affine:\n      self.scale = nn.Parameter(torch.ones(emb_dim))\n      self.shift = nn.Parameter(torch.zeros(emb_dim))\n    else: \n      self.gamma = None ",
        "detail": "model.NeuroX",
        "documentation": {}
    },
    {
        "label": "GELU",
        "kind": 6,
        "importPath": "model.NeuroX",
        "description": "model.NeuroX",
        "peekOfCode": "class GELU(nn.Module): \n  def __init__(self):\n    super().__init__() \n  def forward(self, x):\n    return 0.5 * x * (1 + torch.tanh(\n      torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n      (x + 0.044715 * torch.pow(x, 3))\n    ))\nclass FeedForward(nn.Module): \n  def __init__(self, cfg): ",
        "detail": "model.NeuroX",
        "documentation": {}
    },
    {
        "label": "FeedForward",
        "kind": 6,
        "importPath": "model.NeuroX",
        "description": "model.NeuroX",
        "peekOfCode": "class FeedForward(nn.Module): \n  def __init__(self, cfg): \n    super().__init__() \n    self.layers = nn.Sequential(\n      nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # * 4 to increase model capacity\n      GELU(), \n      nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n    )\n  def forward(self, x): \n    return self.layers(x) ",
        "detail": "model.NeuroX",
        "documentation": {}
    },
    {
        "label": "Encoder",
        "kind": 6,
        "importPath": "model.NeuroX",
        "description": "model.NeuroX",
        "peekOfCode": "class Encoder(nn.Module):\n  def __init__(self, cfg): \n    super().__init__() \n    self.att = MultiHeadAttention(\n      d_in = cfg[\"emb_dim\"],\n      d_out = cfg[\"emb_dim\"],\n      ctx_len = cfg[\"ctx_len\"],\n      num_heads = cfg[\"n_heads\"],\n      dropout = cfg[\"drop_rate\"], \n      qkv_bias= cfg[\"qkv_bias\"])",
        "detail": "model.NeuroX",
        "documentation": {}
    },
    {
        "label": "NeuroX",
        "kind": 6,
        "importPath": "model.NeuroX",
        "description": "model.NeuroX",
        "peekOfCode": "class NeuroX(nn.Module):\n  def __init__(self, cfg):\n    super().__init__()\n    self.input_proj = nn.Linear(cfg[\"input_dim\"], cfg[\"emb_dim\"])\n    self.pos_emb = nn.Embedding(cfg[\"ctx_len\"], cfg[\"emb_dim\"])\n    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n    self.encoder_blocks = nn.Sequential(\n      *[Encoder(cfg) for _ in range(cfg[\"n_layers\"])]\n    )\n    self.final_norm = LayerNorm(cfg[\"emb_dim\"])",
        "detail": "model.NeuroX",
        "documentation": {}
    },
    {
        "label": "cfg",
        "kind": 5,
        "importPath": "model.NeuroX",
        "description": "model.NeuroX",
        "peekOfCode": "cfg = {\n  \"input_dim\": 128,  # Dimension of EEG features\n  \"emb_dim\": 256,    # Embedding dimension\n  \"ctx_len\": 512,    # Context length\n  \"n_heads\": 8,      # Number of attention heads\n  \"drop_rate\": 0.1,  # Dropout rate\n  \"n_layers\": 6,     # Number of transformer layers\n  \"qkv_bias\": True,  # Whether to use bias in QKV linear layers\n  \"num_classes\": 5,  # Number of classes for classification\n}",
        "detail": "model.NeuroX",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "model.NeuroX",
        "description": "model.NeuroX",
        "peekOfCode": "model = NeuroX(cfg)",
        "detail": "model.NeuroX",
        "documentation": {}
    },
    {
        "label": "FeatureExtractionStrategy",
        "kind": 6,
        "importPath": "feature_extraction",
        "description": "feature_extraction",
        "peekOfCode": "class FeatureExtractionStrategy(ABC):\n    @abstractmethod\n    def extract_features(self, epoch, methods: List[str], sfreq):\n        pass\nclass TimeFeatureExtraction(FeatureExtractionStrategy):\n    def __init__(self, methods: List[str]):\n        self.methods = methods\n        self.feature_methods = {\n            'mean': np.mean,\n            # 'median': np.median,",
        "detail": "feature_extraction",
        "documentation": {}
    },
    {
        "label": "TimeFeatureExtraction",
        "kind": 6,
        "importPath": "feature_extraction",
        "description": "feature_extraction",
        "peekOfCode": "class TimeFeatureExtraction(FeatureExtractionStrategy):\n    def __init__(self, methods: List[str]):\n        self.methods = methods\n        self.feature_methods = {\n            'mean': np.mean,\n            # 'median': np.median,\n            'max': np.max,\n            'min': np.min,\n            'std': np.std,\n            'var': np.var,",
        "detail": "feature_extraction",
        "documentation": {}
    },
    {
        "label": "FrequencyFeatureExtraction",
        "kind": 6,
        "importPath": "feature_extraction",
        "description": "feature_extraction",
        "peekOfCode": "class FrequencyFeatureExtraction(FeatureExtractionStrategy):\n    def fft_features(self, epoch, sfreq): \n        n_samples, n_channels = epoch.shape\n        n_fft = n_samples \n        freqs = np.fft.fftfreq(n_fft, d=1/sfreq)\n        fft_feats = np.zeros((n_channels, len(freqs))) \n        for ch in range(n_channels): \n            fft_result = np.fft.fft(epoch[:, ch])\n            fft_magnitude = np.abs(fft_result)\n            fft_magnitude = fft_magnitude[:n_fft // 2]",
        "detail": "feature_extraction",
        "documentation": {}
    },
    {
        "label": "TimeFrequencyFeatureExtraction",
        "kind": 6,
        "importPath": "feature_extraction",
        "description": "feature_extraction",
        "peekOfCode": "class TimeFrequencyFeatureExtraction(FeatureExtractionStrategy):\n  # def __init__(self, info, frequencies, n_cycles, event_id,\n  #              exclude_wavelet=False, exclude_stft=False, exclude_tfr=False):\n      # self.info = info\n      # self.frequencies = frequencies\n      # self.n_cycles = n_cycles\n      # self.event_id = event_id\n      # self.exclude_wavelet = exclude_wavelet\n      # self.exclude_stft = exclude_stft\n      # self.exclude_tfr = exclude_tfr",
        "detail": "feature_extraction",
        "documentation": {}
    },
    {
        "label": "SpatialFeatureExtraction",
        "kind": 6,
        "importPath": "feature_extraction",
        "description": "feature_extraction",
        "peekOfCode": "class SpatialFeatureExtraction(FeatureExtractionStrategy):\n    def __init__(self, info, sfreq, sub_band_ranges, n_components=4):\n        self.info = info\n        self.sfreq = sfreq\n        self.sub_band_ranges = sub_band_ranges\n        self.n_components = n_components\n        self.sub_band_csp = SubBandCSP(sfreq, sub_band_ranges, n_components)\n    def fit(self, X, y):\n        self.sub_band_csp.fit(X, y)\n    def extract_features(self, epoch, sfreq=None):",
        "detail": "feature_extraction",
        "documentation": {}
    },
    {
        "label": "EEGFeatureExtractor",
        "kind": 6,
        "importPath": "feature_extraction",
        "description": "feature_extraction",
        "peekOfCode": "class EEGFeatureExtractor:\n    def __init__(self, info: Info, frequencies: np.ndarray[np.ndarray, np.ndarray], event_id: Dict[str, int]):\n        self.info = info\n        if frequencies is None:\n          self.frequencies = np.concatenate([\n          np.arange(1, 4, 0.5),   # Delta\n          np.arange(4, 8, 0.5),   # Theta\n          np.arange(8, 13, 0.5),  # Alpha\n          np.arange(13, 30, 1),   # Beta\n          np.arange(30, 50, 1)    # Gamma",
        "detail": "feature_extraction",
        "documentation": {}
    },
    {
        "label": "SubBandCSP",
        "kind": 6,
        "importPath": "feature_extraction",
        "description": "feature_extraction",
        "peekOfCode": "class SubBandCSP:\n    def __init__(self, sfreq, sub_band_ranges, n_components=4):\n        self.sfreq = sfreq\n        self.sub_band_ranges = sub_band_ranges\n        self.n_components = n_components\n        self.csp_models = []\n    def bandpass_filter(self, data, low, high, sfreq, order=5):\n        nyquist = 0.5 * sfreq\n        low = low / nyquist\n        high = high / nyquist",
        "detail": "feature_extraction",
        "documentation": {}
    },
    {
        "label": "extract_run_number",
        "kind": 2,
        "importPath": "save_and_load",
        "description": "save_and_load",
        "peekOfCode": "def extract_run_number(filename: str) -> int:\n    \"\"\"\n    Extracts the run number from a filename.\n    Args:\n        filename (str): The filename to extract the run number from.\n    Returns:\n        int: The run number, or a large number if the run number cannot be determined.\n    \"\"\"\n    match = re.search(r'Run (\\d+)', filename)\n    return int(match.group(1)) if match else float('inf')",
        "detail": "save_and_load",
        "documentation": {}
    },
    {
        "label": "load_eeg_data",
        "kind": 2,
        "importPath": "save_and_load",
        "description": "save_and_load",
        "peekOfCode": "def load_eeg_data(baseOutputPath: str, participants: Union[str, List[str]] = 'all') -> Dict[str, List[Raw]]:\n    \"\"\"\n    Loads all processed EEG runs from the base output path into a dictionary.\n    Args:\n        baseOutputPath (str): The base path where the processed EEG data is stored.\n        participants (Union[str, List[str]]): 'all' to load data for all participants, \n                                              a list of participant IDs to load specific participants, \n                                              or a single participant ID to load one participant.\n    Returns:\n        Dict[str, List[Raw]]: A dictionary where keys are participant IDs and values are lists of MNE Raw objects.",
        "detail": "save_and_load",
        "documentation": {}
    },
    {
        "label": "save_processed_files",
        "kind": 2,
        "importPath": "save_and_load",
        "description": "save_and_load",
        "peekOfCode": "def save_processed_files(baseOutputPath: str, sub_fol_name: str, name_of_file: str, eegData: Dict[str, List[Raw]]) -> None:\n    os.makedirs(baseOutputPath, exist_ok=True)\n    for subject_id, raws in eegData.items():\n        subject_output_path = os.path.join(baseOutputPath, f'{sub_fol_name}/{subject_id}')\n        os.makedirs(subject_output_path, exist_ok=True)\n        for run_index, raw in enumerate(raws):\n            output_file_path = os.path.join(subject_output_path, f'{name_of_file} {run_index + 1} raw.fif')\n            raw.save(output_file_path, overwrite=True, verbose=False)\n        print(f'Saved processed runs for {subject_id} to {subject_output_path}')\n# ============================================================================= #",
        "detail": "save_and_load",
        "documentation": {}
    }
]